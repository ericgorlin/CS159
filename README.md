# CS159
Risk Bot, via Lux Delux

If you have any questions ask Eric, he knows how the Lux codebase works.

When getting data don't forget to use -superfast from command line.

**PROGRESS:**
* ChimeraLogged.java- plays one of 4 hard mode AIs against one another and logs the result (Eric)
* ValueNet.py- trains on ChimeraLogged.java's data with PyBrain to estimate probability of winning in certain states
* data1per.txt- data with which to train a value net. One datapoint per game.

**WIP:**
* ValuePlayer.java, which just picks the move which statistically leads to the best state via a value net.

**TODO:**
* Figure out how to talk between python and Java (http interface?) or else redo neural net stuff in java (a fine option, potentially, if we don't need deep learning)
* Test PyBrain nets- do they distinguish properly between worse and better states? Might need deep nets with autogenerated features (and more data?), or something else idk
* See if there is a heads-up setup of the game (right now I'm on no cards, random countries/armies, continent bonuses on first turn, 5% increase per turn) which isn't almost always decided by who goes first
* Create version of ChimeraLogged which gives data on which move we picked instead of who won (can save more than one datapoint per game for this, I think. Just not with valuenets)
* Train policy net on data from policy version of ChimeraLogged
* Make policy player
* Do policy gradient reinforcement learning on policy player
* Test value net on policy gradient reinforcement-trained policy player.
